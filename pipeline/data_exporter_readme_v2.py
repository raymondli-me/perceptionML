#!/usr/bin/env python3
"""Comprehensive README generation without hard-coded line numbers."""

from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import json
import sys

# Import torch to check CUDA availability
try:
    import torch
except ImportError:
    torch = None


def _get_selected_alphas_text(results: Dict[str, Any]) -> str:
    """Format selected alpha values for README display."""
    info = results.get('pc_selection_info', {})
    lines = []
    
    if 'lasso_alpha_x' in info:
        lines.append(f"- Lasso alpha for social_class: {info['lasso_alpha_x']:.6f}")
    if 'lasso_alpha_y' in info:
        lines.append(f"- Lasso alpha for ai_rating: {info['lasso_alpha_y']:.6f}")
    if 'ridge_alpha_x' in info:
        lines.append(f"- Ridge alpha for social_class: {info['ridge_alpha_x']:.6f}")
    if 'ridge_alpha_y' in info:
        lines.append(f"- Ridge alpha for ai_rating: {info['ridge_alpha_y']:.6f}")
    
    return '\n'.join(lines) if lines else '- No alpha values captured in this run'


def generate_comprehensive_readme_v2(output_dir: Path, pipeline: Any, results: Dict[str, Any],
                                    config: Any, exclude_text: bool, anonymize_ids: bool, 
                                    cli_command: Optional[str] = None, versions: Dict[str, str] = None) -> str:
    """Generate comprehensive README with file/function references but no line numbers."""
    
    # Get sampling info
    sampling_info = getattr(pipeline.data_loader, 'sampling_info', None)
    
    readme_content = f"""# PerceptionML Pipeline Export Documentation

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Pipeline Version:** {getattr(pipeline, 'version', '1.0.0')}

## Table of Contents

1. [Overview](#overview)
2. [Command and Configuration](#command-and-configuration)
3. [Privacy and Data Handling](#privacy-and-data-handling)
4. [Sampling Details](#sampling-details)
5. [Directory Structure and File Descriptions](#directory-structure-and-file-descriptions)
6. [Complete Algorithm Documentation](#complete-algorithm-documentation)
7. [Data Processing Pipeline](#data-processing-pipeline)
8. [Model Training Details](#model-training-details)
9. [Export Implementation Details](#export-implementation-details)
10. [Reproducibility Guide](#reproducibility-guide)
11. [Code Architecture](#code-architecture)

---

## Overview

This directory contains a complete export of all data generated by the PerceptionML text analysis pipeline.
The pipeline processes text data through multiple stages of analysis to identify patterns, relationships,
and causal effects between outcomes.

### Key Components Exported

1. **Raw Data and Embeddings** - Original input data and text embeddings
2. **Dimensionality Reduction** - PCA and UMAP results  
3. **Clustering Results** - Topic assignments and keywords
4. **Feature Importance** - PC selection metrics and SHAP values
5. **Causal Analysis** - DML estimates, residuals, and predictions
6. **Visualization Data** - Pre-processed data for 3D visualization

---

## Command and Configuration

### Command Used

```bash
{cli_command or 'python run_pipeline.py [command not captured]'}
```

**Implementation:** Command is captured in `run_pipeline.py` when the pipeline is initialized.
The CLI uses the Click framework for argument parsing.

### Clustering Parameter Options

The pipeline supports flexible clustering configuration via CLI flags:

**Manual Parameters:**
- `--min-cluster-size`: HDBSCAN minimum cluster size
- `--min-samples`: HDBSCAN minimum samples parameter
- `--umap-neighbors`: UMAP n_neighbors parameter
- `--umap-min-dist`: UMAP min_dist parameter

**Auto Mode:**
- `--auto-cluster [few|medium|many]`: Automatically sets parameters based on dataset size
  - `few`: Targets 2-5 clusters
  - `medium`: Targets 5-15 clusters
  - `many`: Targets 15-30 clusters

**Note:** The pipeline always suggests optimal parameters based on your dataset size when it runs.

### Configuration Details

The pipeline configuration is stored in `metadata.json` and includes all parameters used:

```json
{json.dumps(config.to_dict(), indent=2)}
```

**Key Configuration Classes:**
- `PipelineConfig` in `pipeline/config.py` - Main configuration container
- `DataConfig` in `pipeline/config.py` - Data loading and outcome definitions
- `AnalysisConfig` in `pipeline/config.py` - Model hyperparameters

---

## Privacy and Data Handling

### Privacy Settings Applied

- **Text Excluded:** {'Yes' if exclude_text else 'No'}
  - Implementation: `DataExporter._export_raw_data()` method
  - Drops text column before CSV export if enabled

- **IDs Anonymized:** {'Yes' if anonymize_ids else 'No'}
  - Implementation: `DataExporter._export_raw_data()` method
  - Replaces original IDs with sequential integers
  - Creates SHA-256 hash mapping for reference

### Data Handling Process

1. **Text Column Handling**
   - Controlled by `exclude_text` parameter
   - Text column dropped from DataFrame before export

2. **ID Anonymization Process**
   - Original IDs replaced with range(n_samples)
   - SHA-256 hash (truncated to 16 chars) stored in `id_mapping.csv`
   - Preserves referential integrity across all exports

---

{f'''## Sampling Details

### Sampling Configuration

**Implementation:** See `DataLoader._apply_sampling()` method in `pipeline/data_loader.py`

- **Sampling Applied:** Yes
- **Method:** {sampling_info['method']}
- **Original Dataset Size:** {sampling_info['original_size']:,} records
- **Sample Size:** {sampling_info['sample_size']:,} records ({sampling_info['sample_ratio']:.1%} of original)
- **Random Seed:** {sampling_info['sample_seed']}
{f"- **Stratification Column:** {sampling_info['stratify_column']}" if sampling_info.get('stratify_column') else ""}

### Sampling Algorithm

The sampling implementation in `DataLoader._apply_sampling()`:

1. Sets random seeds for reproducibility (numpy and python random)
2. Attempts stratified sampling if categorical outcomes exist
3. Falls back to simple random sampling if stratification fails
4. Stores both sampled and original data
5. Records sampling metadata for documentation

### Sampling Rationale

Datasets larger than 10,000 records can cause:
- **HTML file size issues** - Browser performance degrades with large point clouds
- **Memory constraints** - Embedding generation requires ~4GB per 10k samples
- **Processing time** - UMAP scales as O(n^1.14) for n samples

The sampling preserves statistical properties through:
{f"- Stratification on '{sampling_info['stratify_column']}' to maintain outcome distribution" if sampling_info.get('stratify_column') else "- Random sampling with fixed seed for reproducibility"}
''' if sampling_info else '''## Sampling Details

**No sampling applied** - Processing full dataset
'''}

---

## Directory Structure and File Descriptions

### 01_raw_data/

Contains original input data and text embeddings.

#### Files Generated

{f'''**sampled_data.csv** - The sampled subset used for analysis
- Generated by: `DataExporter._export_raw_data()` method
- Columns: {', '.join(pipeline.data_loader.data.columns.tolist()) if hasattr(pipeline, 'data_loader') else 'N/A'}
- Rows: {len(pipeline.data_loader.data) if hasattr(pipeline, 'data_loader') else 'N/A'}

**original_data_full.csv** - Complete dataset before sampling  
- Contains all records from the original input
- Same column structure as sampled_data.csv
- Rows: {len(pipeline.data_loader.original_data) if hasattr(pipeline.data_loader, 'original_data') and pipeline.data_loader.original_data is not None else 'N/A'}
''' if sampling_info else f'''**original_data.csv** - The complete dataset
- Generated by: `DataExporter._export_raw_data()` method
- Columns: {', '.join(pipeline.data_loader.data.columns.tolist()) if hasattr(pipeline, 'data_loader') else 'N/A'}
- Rows: {len(pipeline.data_loader.data) if hasattr(pipeline, 'data_loader') else 'N/A'}
'''}

**embeddings.csv** - Text embeddings from {config.embedding_model}
- Generated by: `EmbeddingGenerator.generate_embeddings()` in `pipeline/embeddings.py`
- Shape: [{pipeline.embedding_gen.embeddings.shape[0] if hasattr(pipeline, 'embedding_gen') and hasattr(pipeline.embedding_gen, 'embeddings') and pipeline.embedding_gen.embeddings is not None else 'N/A'} × {pipeline.embedding_gen.embeddings.shape[1] if hasattr(pipeline, 'embedding_gen') and hasattr(pipeline.embedding_gen, 'embeddings') and pipeline.embedding_gen.embeddings is not None else 'N/A'}]
- All embeddings are L2-normalized to unit vectors

#### Embedding Generation Process

The `EmbeddingGenerator` class handles text embedding:

1. Loads pre-trained SentenceTransformer model
2. Processes texts in batches of {config.analysis.batch_size}
3. Applies L2 normalization to all embeddings
4. Validates that all embeddings are unit vectors

Key parameters:
- **Model:** {config.embedding_model}
- **Batch size:** {config.analysis.batch_size}
- **Max text length:** {config.analysis.max_text_length} tokens
- **Device:** {'CUDA' if torch and torch.cuda.is_available() else 'CPU'}

---

### 02_dimensionality_reduction/

Results from PCA and UMAP dimensionality reduction.

#### PCA Files

**pca_features.csv** - Principal component scores
- Generated by: `DimensionalityReducer.fit_pca()` method
- Shape: [{len(pipeline.data_loader.data) if hasattr(pipeline, 'data_loader') else 'N/A'} × {config.analysis.pca_components}]
- Standardized before PCA (mean=0, std=1)

**pca_explained_variance.csv** - Variance explained by each PC
- Shows individual and cumulative variance explained
- Total components: {config.analysis.pca_components}

**pca_percentiles.csv** - Percentile rank of each sample on each PC
- Calculated using scipy.stats.rankdata with 'average' method
- Useful for understanding relative positions

**pca_loadings.csv** - Component loadings (if available)
- Shows how each embedding dimension contributes to PCs
- Shape: [embedding_dims × n_components]

#### UMAP Files

**umap_3d.csv** - 3D UMAP coordinates
- Generated by: `DimensionalityReducer.fit_umap()` method
- Normalized to [-1, 1] range for visualization
- Uses cosine metric for high-dimensional data

#### Dimensionality Reduction Details

**PCA Implementation:**
- Standardization with StandardScaler before PCA
- Uses scikit-learn PCA with SVD solver
- Fixed random_state=42 for reproducibility

**UMAP Implementation:**
- Input: First {config.analysis.pca_components} principal components
- Parameters:
  - n_neighbors: {config.analysis.umap_n_neighbors}
  - min_dist: {config.analysis.umap_min_dist}
  - metric: cosine
  - n_components: {config.analysis.umap_dimensions}

---

### 03_clustering/

Topic modeling and clustering results using HDBSCAN.

#### Files Generated

**cluster_assignments.csv** - Cluster/topic assignment for each sample
- Generated by: `TopicModeler.fit_clusters()` method
- Cluster -1 indicates noise points (not assigned to any cluster)
- Includes extracted topic keywords

**topic_summary.csv** - Summary statistics for each topic
- Generated by: `TopicModeler.prepare_topic_visualization()` 
- Contains: topic_id, size, keywords, centroid coordinates

**topic_extreme_stats.csv** - Topic distribution in extreme outcome groups
- Generated by: `TopicModeler.calculate_extreme_group_statistics()`
- Shows over/under-representation in high/low outcome groups

#### Clustering Algorithm

**HDBSCAN Parameters:**
- min_cluster_size: {config.analysis.hdbscan_min_cluster_size}
- min_samples: {config.analysis.hdbscan_min_samples}
- metric: Euclidean (on UMAP coordinates)
- cluster_selection_method: EOM (Excess of Mass)

**Topic Keyword Extraction:**
- Uses c-TF-IDF (class-based TF-IDF)
- Removes English stop words
- Considers unigrams and bigrams
- Selects top 10 keywords per topic

---

### 04_feature_importance/

Feature importance metrics from multiple methods.

#### Files Generated

**feature_importance_summary.csv** - PC importance rankings
- Mutual Information scores and rankings
- XGBoost feature importance and rankings
- Covers all {config.analysis.pca_components} PCs

**pc_selection_summary.csv** - Top 6 PCs by each method (XGBoost, Lasso, Ridge, MI)
- Shows which PCs each method considers most important
- Useful for understanding consensus/disagreement

**regularization_parameters.csv** - Selected regularization parameters (if Lasso/Ridge used)
- Shows alpha values selected by cross-validation
- Includes the alpha range tested
- One row per method/outcome combination

**shap_values_[outcome].csv** - True SHAP values for PC contributions
- Generated for each outcome variable using XGBoost's native method
- Local explanations showing how each PC contributes to predictions
- Columns: ID, PC0_shap_value, PC1_shap_value, ..., PC[n]_shap_value
- Compatible with GPU-trained models (avoids SHAP library serialization issues)

#### Feature Selection Methods

**Mutual Information:**
- Implemented in `DimensionalityReducer.select_top_pcs_for_dml()`
- Uses k-nearest neighbors estimation (k=3)
- Non-parametric measure of dependence

**XGBoost Feature Importance:**
- Uses gain-based importance (average gain across splits)
- Trained with same hyperparameters as DML models
- GPU-accelerated when available

---

### 05_dml_analysis/

Double Machine Learning causal inference results.

#### Main Files

**dml_effects_summary.csv** - All causal effect estimates
- Contains results for all outcome pairs and model types
- Columns: effect, model, theta, se, ci_lower, ci_upper, pval, r2, reduction
- Model types:
  - Naive OLS (no controls)
  - DML - Embeddings (all {pipeline.embedding_gen.embeddings.shape[1] if hasattr(pipeline, 'embedding_gen') and hasattr(pipeline.embedding_gen, 'embeddings') and pipeline.embedding_gen.embeddings is not None else 'N/A'} dimensions)
  - DML - 200 PCs (all principal components)
  - DML - 6 PCs (xgboost) - Selected by XGBoost feature importance
  - DML - 6 PCs (lasso) - Selected by Lasso regularization
  - DML - 6 PCs (ridge) - Selected by Ridge regularization
  - DML - 6 PCs (mi) - Selected by Mutual Information

**model_diagnostics.csv** - Model fit statistics
- Cross-validated R² for each outcome
- First-stage prediction accuracy

**r2_comparison.csv** - Comparison of cross-validated vs non-cross-validated R²
- Shows R² values for both CV and non-CV (full dataset) models
- Columns: effect, model, r2_y_cv, r2_x_cv, r2_y_full, r2_x_full, r2_y_diff, r2_x_diff
- Useful for assessing overfitting (large positive differences suggest overfitting)

#### Residuals Directory (Cross-validated)

Contains first-stage residuals from DML cross-fitting:
- Files: `residuals_[treatment]_to_[outcome]_[model].csv`
- Model suffixes: `embeddings`, `200pcs`, `top6pcs_[method]`
- Columns: ID, residual_outcome, residual_treatment

#### Residuals_noncv Directory (Non-cross-validated)

Contains first-stage residuals from full dataset training:
- Files: `residuals_[treatment]_to_[outcome]_[model].csv`
- Model suffixes: `embeddings`, `200pcs`, `top6pcs_[method]`
- Columns: ID, residual_outcome, residual_treatment
- These are computed by training on the full dataset and predicting on the same data

**Purpose:** These residuals are the core of DML estimation and can be used to:
- Reproduce the causal effect estimates
- Perform diagnostic checks
- Create residual plots

#### Predictions Directory (Cross-validated)

Contains first-stage predictions from DML cross-fitting:
- Files: `predictions_[treatment]_to_[outcome]_[model].csv`
- Same model suffixes as residuals
- Columns: ID, predicted_outcome, predicted_treatment

#### Predictions_noncv Directory (Non-cross-validated)

Contains first-stage predictions from full dataset training:
- Files: `predictions_[treatment]_to_[outcome]_[model].csv`
- Same model suffixes as residuals
- Columns: ID, predicted_outcome, predicted_treatment
- These are computed by training on the full dataset and predicting on the same data

#### PC Selection Method Subdirectories

For each PC selection method (xgboost, lasso, ridge, mi), there is a subdirectory:
- `by_method_[method]/` containing:
  - `residuals/` - Cross-validated residuals for this method
  - `residuals_noncv/` - Non-cross-validated residuals
  - `predictions/` - Cross-validated predictions
  - `predictions_noncv/` - Non-cross-validated predictions

**PC Selection Methods:**
- **xgboost**: Uses gradient boosting feature importance averaging across treatment/outcome
- **lasso**: Uses L1 regularization coefficient magnitudes
- **ridge**: Uses L2 regularization coefficient magnitudes  
- **mi**: Uses mutual information scores

**Purpose:** Verify that residuals = actual - predicted

#### DML Algorithm Overview

The `DMLAnalyzer` class implements:

1. **Cross-fitting** with {config.analysis.dml_n_folds} folds
2. **Nuisance models** using XGBoost regressors
3. **Orthogonalization** of treatment and outcome
4. **Robust standard errors** for inference

Key implementation details:
- Each fold trains separate models for treatment and outcome
- Predictions made on held-out data to avoid overfitting
- Final estimate: θ = Σ(r_x * r_y) / Σ(r_x²)
- Standard errors account for estimation uncertainty

---

### 06_pc_analysis/

Detailed PC-level analysis and effects.

#### Files Generated

**pc_global_effects.csv** - Probability changes for extreme PC values
- Generated by: `TextEmbeddingPipeline._calculate_pc_global_effects()`
- Compares outcomes at 90th vs 10th percentile of each PC
- Uses logistic regression on all PCs simultaneously

**pc_detailed_stats.csv** - Comprehensive PC statistics
- Generated by: `TextEmbeddingPipeline._calculate_pc_detailed_stats()`
- Includes: importance rankings, correlations, SHAP statistics
- Cross-validated rankings for robustness

**pc_topic_associations.csv** - PC-topic relationships
- Statistical tests (Welch's t-test) for PC differences across topics
- Effect sizes and p-values for each PC-topic pair

---

### 07_visualization_ready/

Pre-processed data for interactive 3D visualization.

#### Files Generated

**point_cloud.csv** - Complete visualization data
- All coordinates, outcomes, categories, and metadata
- Ready for Three.js rendering

**category_labels.csv** - High/low category assignments
- Categories based on outcome thresholds:
  - both_high: Both outcomes > 80th percentile
  - first_high: First > 80th, Second < 20th
  - second_high: Second > 80th, First < 20th
  - both_low: Both outcomes < 20th percentile
  - middle: All other points

**thresholds.csv** - Outcome thresholds used
- 20th percentile (low threshold)
- 80th percentile (high threshold)

---

## Complete Algorithm Documentation

### 1. Text Embedding Generation

**Model:** {config.embedding_model}
**Implementation:** `EmbeddingGenerator` class in `pipeline/embeddings.py`

**Process:**
1. Load pre-trained SentenceTransformer model
2. Set device to CUDA if available
3. Process texts in batches
4. Apply L2 normalization
5. Validate all embeddings are unit vectors

**Key Methods:**
- `generate_embeddings()`: Main embedding generation
- `validate_embeddings()`: Ensures quality and consistency

### 2. Principal Component Analysis (PCA)

**Implementation:** `DimensionalityReducer.fit_pca()` in `pipeline/dimensionality.py`
**Library:** scikit-learn {versions.get('scikit-learn', 'unknown')}

**Configuration:**
- Components: {config.analysis.pca_components}
- Preprocessing: StandardScaler (mean=0, std=1)
- Random state: 42

**Output:**
- Principal component scores
- Explained variance ratios
- Percentile ranks for interpretability

### 3. UMAP (Uniform Manifold Approximation and Projection)

**Implementation:** `DimensionalityReducer.fit_umap()` in `pipeline/dimensionality.py`
**Library:** umap-learn {versions.get('umap-learn', 'unknown')}

**Configuration:**
- Input: PCA features (first {config.analysis.pca_components} components)
- Output dimensions: {config.analysis.umap_dimensions}
- n_neighbors: {config.analysis.umap_n_neighbors}
- min_dist: {config.analysis.umap_min_dist}
- Metric: cosine
- Normalization: Linear scaling to [-1, 1]

### 4. HDBSCAN Clustering

**Implementation:** `TopicModeler.fit_clusters()` in `pipeline/clustering.py`

**Configuration:**
- min_cluster_size: {config.analysis.hdbscan_min_cluster_size}
- min_samples: {config.analysis.hdbscan_min_samples}
- Input: UMAP coordinates
- Noise handling: Points not in clusters labeled as -1

### 5. Topic Keyword Extraction

**Implementation:** `TopicModeler.extract_topics()` in `pipeline/clustering.py`

**Process:**
1. Concatenate texts by cluster
2. Apply TF-IDF vectorization
3. Remove stop words
4. Consider unigrams and bigrams
5. Select top 10 keywords by TF-IDF score

### 6. Feature Importance Analysis

**Multiple methods implemented:**

1. **Mutual Information** - Non-parametric dependence measure
2. **XGBoost Feature Importance** - Tree-based importance scores  
3. **Lasso Feature Selection** - L1 regularization coefficient magnitudes
4. **Ridge Feature Selection** - L2 regularization coefficient magnitudes
5. **SHAP Values** - True SHAP values calculated using XGBoost's native method (GPU-compatible)

### 7. PC Global Effects Analysis

**Implementation:** `_calculate_pc_global_effects()` in `run_pipeline.py`

**Purpose:** Quantifies how movement along each principal component affects outcome probabilities.

**Calculated Probabilities:**
- `prob_high_if_high`: P(outcome > high_threshold | PC is high)
- `prob_high_if_low`: P(outcome > high_threshold | PC is low)
- `prob_low_if_high`: P(outcome < low_threshold | PC is high)  
- `prob_low_if_low`: P(outcome < low_threshold | PC is low)
- `high_diff`: Effect size for high outcome (prob_high_if_high - prob_high_if_low)
- `low_diff`: Effect size for low outcome (prob_low_if_high - prob_low_if_low)

**Important Note on Probabilities:**
- When sufficient variation exists in outcomes, logistic regression estimates conditional probabilities
- When no variation exists (e.g., all outcomes = 0), the marginal probability (base rate) is reported
- All values are true probabilities between 0 and 1, not arbitrary scores
- Example: If 5% of samples have outcome=1 and PC doesn't predict it, all probabilities ≈ 0.05

**PC Selection for DML:**
The pipeline implements multiple PC selection methods to identify the most informative components:
- **XGBoost**: Averages feature importance across treatment and outcome models
- **Lasso**: Uses LassoCV with cross-validation to select optimal regularization
- **Ridge**: Uses RidgeCV with multiple alpha values
- **Mutual Information**: Calculates MI scores for each outcome and averages

**Regularization Parameter Selection:**
{f'''
Lasso and Ridge methods use cross-validation to automatically select optimal alpha values:

- **Lasso Alpha Range**: {config.analysis.lasso_alphas or 'default range'}
- **Ridge Alpha Range**: {config.analysis.ridge_alphas or [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}
- **CV Folds**: {config.analysis.regularization_cv_folds or 5}

**Selected Alpha Values** (if available):
{_get_selected_alphas_text(results) if results.get('pc_selection_info') else '- Alpha selection details available in 04_feature_importance/regularization_parameters.csv'}
''' if 'pc_selection_info' in results else ''}

**Key Functions:**
- `DimensionalityReducer.select_top_pcs_for_dml()` - PC selection with multiple methods
- `DMLAnalyzer._calculate_contributions()` - Native XGBoost SHAP value calculation

### 8. Double Machine Learning (DML)

**Implementation:** `DMLAnalyzer` class in `pipeline/dml_analysis.py`
**Library:** XGBoost {versions.get('xgboost', 'unknown')}

**Algorithm Steps:**
1. Split data into {config.analysis.dml_n_folds} folds
2. For each fold:
   - Train XGBoost models for treatment and outcome on training data
   - Predict on test fold
   - Calculate residuals
3. Estimate causal effect: θ = Σ(r_x * r_y) / Σ(r_x²)
4. Calculate robust standard errors

**Model Configurations:**
- n_estimators: {config.analysis.xgb_n_estimators}
- max_depth: {config.analysis.xgb_max_depth}
- GPU acceleration when available

**Model Variants:**
1. Raw embeddings - Uses all embedding dimensions
2. 200 PCs - Uses all principal components
3. Top 6 PCs - Multiple selection methods:
   - XGBoost (default/primary): Components selected by XGBoost feature importance
   - Lasso: Components selected by L1 regularization
   - Ridge: Components selected by L2 regularization
   - Mutual Information: Components selected by MI scores
   
**Configuration Options:**
- `--pc-selection-methods`: Choose which methods to run (default: all)
- `--primary-pc-method`: Set primary method for downstream analysis (default: xgboost)

### 8. PC Effect Analysis

**Implementation:** `TextEmbeddingPipeline._calculate_pc_global_effects()`

**Method:**
1. Standardize all PC values
2. For each PC:
   - Set PC to 90th percentile (all others at 0)
   - Set PC to 10th percentile (all others at 0)
   - Use logistic regression to predict outcome probabilities
   - Calculate probability differences

### 9. Statistical Analysis

**PC-Topic Associations:**
- Welch's t-test for unequal variances
- Compares PC values for topic members vs non-members
- No multiple testing correction applied

**Cross-validation for Rankings:**
- 5-fold CV for robust importance estimates
- Reports average and median ranks

---

## Data Processing Pipeline

### Execution Flow

1. **Data Loading** (`DataLoader` class)
   - Load CSV with pandas
   - Apply sampling if configured
   - Validate outcome columns

2. **Text Embedding** (`EmbeddingGenerator` class)
   - Load pre-trained transformer
   - Batch process texts
   - Normalize embeddings

3. **Dimensionality Reduction**
   - PCA on embeddings → 200 components
   - UMAP on PCA features → 3D coordinates

4. **Clustering** (`TopicModeler` class)
   - HDBSCAN on UMAP coordinates
   - Extract topic keywords with TF-IDF

5. **Feature Selection**
   - Calculate mutual information
   - Train XGBoost, Lasso, and Ridge models
   - Select top 6 PCs using average importance:
     - Compute importance for X and Y separately
     - Average the importance scores
     - Select top 6 by average importance

6. **Causal Analysis** (`DMLAnalyzer` class)
   - Run DML with three feature sets
   - Export residuals and predictions
   - Calculate effect estimates

7. **Visualization Prep**
   - Calculate thresholds and categories
   - Compute PC effects
   - Generate statistics

8. **Export** (`DataExporter` class)
   - Save all intermediate results
   - Generate documentation

---

## Model Training Details

### XGBoost Configuration

**For Feature Selection:**
- n_estimators: {config.analysis.xgb_n_estimators}
- max_depth: 6 (fixed for selection)
- tree_method: 'hist' (histogram-based)
- device: 'cuda' (when available)

**For DML Nuisance Models:**
- n_estimators: {config.analysis.xgb_n_estimators}
- max_depth: {config.analysis.xgb_max_depth}
- Other parameters at defaults

### Logistic Regression (PC Effects)

- Solver: 'lbfgs'
- max_iter: 1000
- No regularization (C=1.0)
- Used for binary outcome modeling

---

## Export Implementation Details

### Export Process

The `DataExporter` class orchestrates the export:

1. Creates timestamped output directory
2. Exports each data category with error handling
3. Generates comprehensive documentation
4. Logs any warnings to `export_warnings.txt`

### Multi-Model Support

Recent enhancement allows exporting residuals/predictions for all DML models:
- Residuals stored with model suffix in filename
- Enables comparison across feature sets
- Supports reproducibility analysis

### Error Handling

Each export section wrapped in try/except blocks:
- Continues export even if one section fails
- Collects all warnings for summary
- Ensures partial exports are still useful

---

## Reproducibility Guide

### Environment Setup

```bash
# Create virtual environment
python -m venv perceptionml_env
source perceptionml_env/bin/activate  # Linux/Mac
# or
perceptionml_env\\Scripts\\activate  # Windows

# Install dependencies with exact versions
pip install numpy=={versions.get('numpy', 'X.X.X')}
pip install pandas=={versions.get('pandas', 'X.X.X')}
pip install scikit-learn=={versions.get('scikit-learn', 'X.X.X')}
pip install umap-learn=={versions.get('umap-learn', 'X.X.X')}
pip install xgboost=={versions.get('xgboost', 'X.X.X')}
pip install torch=={versions.get('torch', 'X.X.X')}
pip install transformers=={versions.get('transformers', 'X.X.X')}
```

### Reproducing Results

#### From Exported Data (Cross-validated)

```python
import pandas as pd
import numpy as np

# Load cross-validated residuals
residuals = pd.read_csv('05_dml_analysis/residuals/residuals_X_to_Y_200pcs.csv')

# Reproduce DML estimate
theta = np.sum(residuals['residual_treatment'] * residuals['residual_outcome']) / \\
        np.sum(residuals['residual_treatment'] ** 2)

# Standard error
n = len(residuals)
se = np.sqrt(np.sum((residuals['residual_outcome'] - theta * residuals['residual_treatment']) ** 2) / 
             (n * np.sum(residuals['residual_treatment'] ** 2)))

print(f"CV Theta: {{theta:.4f}}, SE: {{se:.4f}}")
```

#### Comparing CV vs Non-CV Results

```python
# Load both CV and non-CV residuals
residuals_cv = pd.read_csv('05_dml_analysis/residuals/residuals_X_to_Y_200pcs.csv')
residuals_noncv = pd.read_csv('05_dml_analysis/residuals_noncv/residuals_X_to_Y_200pcs.csv')

# Compare R-squared values
r2_comp = pd.read_csv('05_dml_analysis/r2_comparison.csv')
print("R² Comparison:")
print(r2_comp[r2_comp['effect'] == 'X → Y'][['model', 'r2_y_cv', 'r2_y_full', 'r2_y_diff']])

# Verify residuals calculation
predictions_noncv = pd.read_csv('05_dml_analysis/predictions_noncv/predictions_X_to_Y_200pcs.csv')
original = pd.read_csv('01_raw_data/original_data.csv')
merged = predictions_noncv.merge(original, on='id')

# Check that residuals = actual - predicted
calc_resid_Y = merged['Y'] - merged['predicted_outcome']
print(f"Residuals match: {{np.allclose(calc_resid_Y, residuals_noncv['residual_outcome'])}}")
```

#### From Saved State

```bash
python run_pipeline.py --import-state [state_file.pkl] -o new_visualization.html
```

### Random Seeds

Fixed seeds used throughout:
- General: 42
- NumPy: Set when sampling
- Python random: Set when sampling
- All models: random_state=42

---

## Code Architecture

### Core Modules

1. **run_pipeline.py**
   - Main orchestrator
   - CLI interface using Click
   - Pipeline coordination

2. **pipeline/config.py**
   - Configuration dataclasses
   - YAML parsing
   - Validation logic

3. **pipeline/data_loader.py**
   - CSV loading and validation
   - Sampling implementation
   - Threshold calculations

4. **pipeline/embeddings.py**
   - SentenceTransformer wrapper
   - Batch processing
   - Embedding validation

5. **pipeline/dimensionality.py**
   - PCA implementation
   - UMAP implementation
   - Feature selection methods

6. **pipeline/clustering.py**
   - HDBSCAN clustering
   - Topic extraction
   - Cluster statistics

7. **pipeline/dml_analysis.py**
   - DML estimation
   - Cross-fitting logic
   - Multi-model support

8. **pipeline/visualization.py**
   - HTML generation
   - JavaScript integration
   - Interactive features

9. **pipeline/data_exporter.py**
   - CSV export logic
   - State serialization
   - Documentation generation

### Key Design Patterns

- **Pipeline Pattern**: Sequential processing stages
- **Strategy Pattern**: Multiple embedding/clustering options
- **Factory Pattern**: Configuration-based component creation
- **Observer Pattern**: Progress reporting during processing

---

## Questions or Issues?

For questions about this export or the PerceptionML pipeline:
1. Check the code architecture section above
2. Refer to function/class names for implementation details
3. Use the exported data to verify calculations
4. Contact the maintainers for support

**Generated by:** PerceptionML v{getattr(pipeline, 'version', '1.0.0')}
**Export version:** 1.0.0
"""
    
    return readme_content